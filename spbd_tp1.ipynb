{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diogocristovao/SPBD_tp1/blob/main/spbd_tp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT3ms58h5G7Y"
      },
      "outputs": [],
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the dataset\n",
        "\n",
        "!wget -q -O energy-readings.csv https://raw.githubusercontent.com/smduarte/spbd-2425/refs/heads/main/docs/labs/projs/energy-readings.csv\n",
        "!head -10 energy-readings.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X3HBc8F8LOh",
        "outputId": "64e6e489-72de-4da2-d850-8c44bd53e34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date;sensor;energy\n",
            "2024-02-01 00:00:00;D;2615.0\n",
            "2024-02-01 00:00:18;C;1098.8\n",
            "2024-02-01 00:00:25;A;650.5\n",
            "2024-02-01 00:00:33;J;966.7\n",
            "2024-02-01 00:00:42;H;2145.4\n",
            "2024-02-01 00:00:54;E;1874.0\n",
            "2024-02-01 00:01:52;K;841.2\n",
            "2024-02-01 00:02:00;E;1874.1\n",
            "2024-02-01 00:02:20;I;927.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "\t\t\t\t\t\t.appName('energy').getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "try :\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                             sep =';', header=True, inferSchema=True)\n",
        "\n",
        "    readings.printSchema()\n",
        "\n",
        "\n",
        "    readings.show(11)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK9Kh1B95PNn",
        "outputId": "27213ced-da59-462b-e367-37781e17e79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- sensor: string (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            "\n",
            "+-------------------+------+------+\n",
            "|               date|sensor|energy|\n",
            "+-------------------+------+------+\n",
            "|2024-02-01 00:00:00|     D|2615.0|\n",
            "|2024-02-01 00:00:18|     C|1098.8|\n",
            "|2024-02-01 00:00:25|     A| 650.5|\n",
            "|2024-02-01 00:00:33|     J| 966.7|\n",
            "|2024-02-01 00:00:42|     H|2145.4|\n",
            "|2024-02-01 00:00:54|     E|1874.0|\n",
            "|2024-02-01 00:01:52|     K| 841.2|\n",
            "|2024-02-01 00:02:00|     E|1874.1|\n",
            "|2024-02-01 00:02:20|     I| 927.2|\n",
            "|2024-02-01 00:02:36|     K| 841.3|\n",
            "|2024-02-01 00:03:24|     G| 833.7|\n",
            "+-------------------+------+------+\n",
            "only showing top 11 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Configura a Spark Session\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "                    .appName('energy').getOrCreate()\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "try:\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                              sep=';', header=True, inferSchema=True)\n",
        "\n",
        "    # Imprime o esquema dos dados\n",
        "    readings.printSchema()\n",
        "\n",
        "    # Filtra apenas os dados de fevereiro de 2024\n",
        "    readings_february = readings.filter((year(\"date\") == 2024) & (month(\"date\") == 2))\n",
        "\n",
        "    # Calcula o valor máximo e mínimo de energia para cada sensor no mês de fevereiro\n",
        "    energy_per_sensor = readings_february.groupBy(\"sensor\").agg(\n",
        "        max(\"energy\").alias(\"max_energy\"),\n",
        "        min(\"energy\").alias(\"min_energy\")\n",
        "    ).orderBy(\"sensor\")\n",
        "\n",
        "    # Exibe o valor máximo e mínimo de energia de cada sensor no mês de fevereiro\n",
        "    energy_per_sensor.show()\n",
        "\n",
        "except Exception as err:\n",
        "   print(err)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lXLG-peP1tt",
        "outputId": "d25067de-1647-4d63-8e5e-8e64e548255d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- sensor: string (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            "\n",
            "+------+----------+----------+\n",
            "|sensor|max_energy|min_energy|\n",
            "+------+----------+----------+\n",
            "|     A|    816.88|     650.5|\n",
            "|     B|    757.31|     627.5|\n",
            "|     C|   1356.02|    1098.8|\n",
            "|     D|    3102.4|    2615.0|\n",
            "|     E|   2322.76|    1874.0|\n",
            "|     F|    908.41|     748.0|\n",
            "|     G|   1002.17|     833.7|\n",
            "|     H|    2625.0|    2145.4|\n",
            "|     I|   1278.61|     927.2|\n",
            "|     J|   1197.55|     966.7|\n",
            "|     K|    1067.7|     841.2|\n",
            "+------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Alinea a)\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Configura a Spark Session\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "                    .appName('energy').getOrCreate()\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "try:\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                              sep=';', header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "    # Filtra apenas os dados de fevereiro de 2024\n",
        "    readings = readings.filter((year(\"date\") == 2024) & (month(\"date\") == 2))\n",
        "\n",
        "    # Para cada sensor, queremos encontrar o valor de energia inicial e final em fevereiro\n",
        "    # Usa o primeiro e o último valor de energia de cada sensor para calcular o consumo total\n",
        "    total_energy = readings.groupBy(\"sensor\").agg(\n",
        "        round((max(\"energy\") - min(\"energy\")), 2).alias(\"total_energy_consumed (Kwh)\")\n",
        "    ).orderBy(\"sensor\")\n",
        "\n",
        "    # Calcula a soma da energia total gasta por todos os sensores\n",
        "    total_energy_sum = total_energy.agg(round(sum(\"total_energy_consumed (Kwh)\"), 2).alias(\"total_energy_all_sensors\")).collect()[0][\"total_energy_all_sensors\"]\n",
        "\n",
        "\n",
        "\n",
        "    # Exibe o consumo total de energia de cada sensor\n",
        "    total_energy.show()\n",
        "\n",
        "     # Exibe a soma da energia total gasta pelos 11 sensores\n",
        "    print(\"Total energy consumed by all sensors:\", total_energy_sum, \"(Kwh)\")\n",
        "\n",
        "\n",
        "except Exception as err:\n",
        "   print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KFXxYGYAGnH",
        "outputId": "c1ed7130-74ea-4764-b100-94d119137f21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------------+\n",
            "|sensor|total_energy_consumed (Kwh)|\n",
            "+------+---------------------------+\n",
            "|     A|                     166.38|\n",
            "|     B|                     129.81|\n",
            "|     C|                     257.22|\n",
            "|     D|                      487.4|\n",
            "|     E|                     448.76|\n",
            "|     F|                     160.41|\n",
            "|     G|                     168.47|\n",
            "|     H|                      479.6|\n",
            "|     I|                     351.41|\n",
            "|     J|                     230.85|\n",
            "|     K|                      226.5|\n",
            "+------+---------------------------+\n",
            "\n",
            "Total energy consumed by all sensors: 3106.81 (Kwh)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Alinea b)\n",
        "\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Configura a Spark Session\n",
        "spark = SparkSession.builder.master('local[*]') \\\n",
        "                    .appName('energy').getOrCreate()\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "try:\n",
        "    readings = spark.read.csv('energy-readings.csv',\n",
        "                              sep=';', header=True, inferSchema=True)\n",
        "\n",
        "    # Filtra apenas os dados de fevereiro de 2024\n",
        "    readings = readings.filter((year(\"date\") == 2024) & (month(\"date\") == 2))\n",
        "\n",
        "    # Extrai a data (sem o tempo) para agrupar por dia\n",
        "    readings = readings.withColumn(\"date\", to_date(\"date\"))\n",
        "\n",
        "    # Usa Window Functions para pegar a última leitura de cada sensor por dia\n",
        "    window_spec = Window.partitionBy(\"sensor\", \"date\").orderBy(desc(\"date\"))\n",
        "    daily_last_reading = readings.withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
        "                                 .filter(col(\"row_number\") == 1) \\\n",
        "                                 .drop(\"row_number\")\n",
        "\n",
        "    daily_running_total = daily_last_reading.groupBy(\"date\").agg(\n",
        "        round(sum(\"energy\"), 2).alias(\"running_total_energy (Kwh)\")\n",
        "    ).orderBy(\"date\")\n",
        "\n",
        "    # Exibe o total acumulado de energia consumida por dia\n",
        "    daily_running_total.show(truncate=False)\n",
        "\n",
        "except Exception as err:\n",
        "   print(err)"
      ],
      "metadata": {
        "id": "GTbjymauxVMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ff643c-6a0d-46eb-f7e9-bafe3cf7d55f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------------+\n",
            "|date      |running_total_energy (Kwh)|\n",
            "+----------+--------------------------+\n",
            "|2024-02-01|13328.0                   |\n",
            "|2024-02-02|13448.3                   |\n",
            "|2024-02-09|14377.2                   |\n",
            "|2024-02-10|14433.5                   |\n",
            "|2024-02-11|14547.6                   |\n",
            "|2024-02-12|14665.6                   |\n",
            "|2024-02-13|14776.3                   |\n",
            "|2024-02-14|14889.3                   |\n",
            "|2024-02-15|14982.4                   |\n",
            "|2024-02-16|15063.8                   |\n",
            "|2024-02-18|15293.6                   |\n",
            "|2024-02-19|15351.6                   |\n",
            "|2024-02-20|15431.4                   |\n",
            "|2024-02-21|15515.4                   |\n",
            "|2024-02-22|15598.5                   |\n",
            "|2024-02-23|15675.4                   |\n",
            "|2024-02-24|15839.8                   |\n",
            "|2024-02-25|15903.37                  |\n",
            "|2024-02-26|16003.19                  |\n",
            "|2024-02-27|16095.89                  |\n",
            "+----------+--------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "For each sensor, separately:\n",
        "Compute the total energy consumed and the average energy consumption per day.\n"
      ],
      "metadata": {
        "id": "Z6TKNnOqM6k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, max, min, countDistinct, month, to_date, round\n",
        "\n",
        "# Configura a Spark Session\n",
        "spark = SparkSession.builder.master('local[*]').appName('energy').getOrCreate()\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "try:\n",
        "    readings = spark.read.csv('energy-readings.csv', sep=';', header=True, inferSchema=True)\n",
        "\n",
        "    # Certifique-se de que a coluna 'date' está no formato de data\n",
        "    readings = readings.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "    # Filtra apenas os dados de fevereiro de 2024\n",
        "    readings = readings.filter((month(\"date\") == 2))\n",
        "\n",
        "    # Calcula o consumo total de energia para cada sensor\n",
        "    total_energy = readings.groupBy(\"sensor\").agg(\n",
        "        round((max(\"energy\") - min(\"energy\")), 2).alias(\"total_energy_consumed (Kwh)\")\n",
        "    )\n",
        "\n",
        "    # Calcula o número de dias de leitura em fevereiro para cada sensor\n",
        "    days_count = readings.groupBy(\"sensor\").agg(countDistinct(\"date\").alias(\"days_count\")).orderBy(\"sensor\")\n",
        "\n",
        "    # Exibe a coluna \"days_count\" para cada sensor\n",
        "    print(\"Número de dias de leitura (days_count) para cada sensor:\")\n",
        "    days_count.show()\n",
        "\n",
        "    # Junta os dados de total de energia e de contagem de dias\n",
        "    total_energy = total_energy.join(days_count, on=\"sensor\")\n",
        "\n",
        "    # Calcula o consumo médio de energia por dia para cada sensor com arredondamento\n",
        "    total_energy = total_energy.withColumn(\n",
        "        \"average_daily_energy_consumed (Kwh)\", round(col(\"total_energy_consumed (Kwh)\") / col(\"days_count\"), 2)\n",
        "    )\n",
        "\n",
        "    # Exibe o consumo total de energia e o consumo médio diário de cada sensor, ordenado por sensor\n",
        "    total_energy.select(\"sensor\", \"total_energy_consumed (Kwh)\", \"average_daily_energy_consumed (Kwh)\") \\\n",
        "                .orderBy(\"sensor\") \\\n",
        "                .show()\n",
        "\n",
        "except Exception as err:\n",
        "    print(\"Erro:\", err)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvmfervkNEyA",
        "outputId": "97f375a1-7e74-4dca-fc50-a63c62f1699c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de dias de leitura (days_count) para cada sensor:\n",
            "+------+----------+\n",
            "|sensor|days_count|\n",
            "+------+----------+\n",
            "|     A|        22|\n",
            "|     B|        22|\n",
            "|     C|        22|\n",
            "|     D|        22|\n",
            "|     E|        22|\n",
            "|     F|        22|\n",
            "|     G|        22|\n",
            "|     H|        22|\n",
            "|     I|        22|\n",
            "|     J|        22|\n",
            "|     K|        22|\n",
            "+------+----------+\n",
            "\n",
            "+------+---------------------------+-----------------------------------+\n",
            "|sensor|total_energy_consumed (Kwh)|average_daily_energy_consumed (Kwh)|\n",
            "+------+---------------------------+-----------------------------------+\n",
            "|     A|                     166.38|                               7.56|\n",
            "|     B|                     129.81|                                5.9|\n",
            "|     C|                     257.22|                              11.69|\n",
            "|     D|                      487.4|                              22.15|\n",
            "|     E|                     448.76|                               20.4|\n",
            "|     F|                     160.41|                               7.29|\n",
            "|     G|                     168.47|                               7.66|\n",
            "|     H|                      479.6|                               21.8|\n",
            "|     I|                     351.41|                              15.97|\n",
            "|     J|                     230.85|                              10.49|\n",
            "|     K|                      226.5|                               10.3|\n",
            "+------+---------------------------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each sensor, separately:\n",
        "\n",
        "Compute the day of the month with minimum and maximum energy consumption."
      ],
      "metadata": {
        "id": "qnwenN2RRpoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, min, max, month, to_date, first, last, round\n",
        "\n",
        "# Configura a Spark Session\n",
        "spark = SparkSession.builder.master('local[*]').appName('energy').getOrCreate()\n",
        "\n",
        "# Carrega o arquivo CSV\n",
        "try:\n",
        "    # Carrega o arquivo CSV e converte a coluna 'date' para o tipo de data\n",
        "    readings = spark.read.csv('energy-readings.csv', sep=';', header=True, inferSchema=True)\n",
        "    readings = readings.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "    # Filtra apenas os dados de fevereiro de 2024\n",
        "    readings_february = readings.filter((month(\"date\") == 2))\n",
        "\n",
        "    # Para cada sensor e dia, obtemos a primeira e última leitura do dia\n",
        "    daily_consumption = readings_february.groupBy(\"sensor\", \"date\").agg(\n",
        "        first(\"energy\").alias(\"first_reading\"),\n",
        "        last(\"energy\").alias(\"last_reading\")\n",
        "    )\n",
        "\n",
        "    # Calcula o consumo diário de energia\n",
        "    daily_consumption = daily_consumption.withColumn(\n",
        "        \"daily_energy_consumption\", col(\"last_reading\") - col(\"first_reading\")\n",
        "    )\n",
        "\n",
        "    # Identifica o dia com o consumo mínimo e máximo de energia para cada sensor\n",
        "    min_consumption_day = daily_consumption.groupBy(\"sensor\").agg(\n",
        "        round(min(\"daily_energy_consumption\"), 3).alias(\"min_daily_energy\"),\n",
        "        first(\"date\").alias(\"day_min_consumption\")  # Ajustar para mostrar o dia correto\n",
        "    )\n",
        "\n",
        "    max_consumption_day = daily_consumption.groupBy(\"sensor\").agg(\n",
        "        round(max(\"daily_energy_consumption\"), 3).alias(\"max_daily_energy\"),\n",
        "        last(\"date\").alias(\"day_max_consumption\")  # Ajustar para mostrar o dia correto\n",
        "    )\n",
        "\n",
        "    # Junte os resultados para ter ambos os dias em uma única tabela\n",
        "    result = min_consumption_day.join(max_consumption_day, on=\"sensor\")\n",
        "\n",
        "    # Exibe os dias de consumo mínimo e máximo de energia para cada sensor, ordenado por sensor\n",
        "    result.select(\"sensor\", \"day_min_consumption\", \"min_daily_energy\", \"day_max_consumption\", \"max_daily_energy\") \\\n",
        "          .orderBy(\"sensor\") \\\n",
        "          .show()\n",
        "\n",
        "except Exception as err:\n",
        "    print(\"Erro:\", err)\n"
      ],
      "metadata": {
        "id": "CnN3sD6H3Ok_",
        "outputId": "bf16bb6a-bfe1-4d66-f449-a3473a9945ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+----------------+-------------------+----------------+\n",
            "|sensor|day_min_consumption|min_daily_energy|day_max_consumption|max_daily_energy|\n",
            "+------+-------------------+----------------+-------------------+----------------+\n",
            "|     A|         2024-02-28|            0.77|         2024-02-23|             8.1|\n",
            "|     B|         2024-02-26|             0.1|         2024-02-22|             9.9|\n",
            "|     C|         2024-02-23|             1.6|         2024-02-12|            14.0|\n",
            "|     D|         2024-02-11|             5.7|         2024-02-21|            26.4|\n",
            "|     E|         2024-02-16|             4.7|         2024-02-13|            20.6|\n",
            "|     F|         2024-02-27|             0.8|         2024-02-09|           12.87|\n",
            "|     G|         2024-02-22|             0.7|         2024-02-18|             9.3|\n",
            "|     H|         2024-02-15|             2.1|         2024-02-20|           26.11|\n",
            "|     I|         2024-02-02|             0.5|         2024-02-23|           20.66|\n",
            "|     J|         2024-02-09|             1.7|         2024-02-28|            10.0|\n",
            "|     K|         2024-02-14|             1.2|         2024-02-20|            10.2|\n",
            "+------+-------------------+----------------+-------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}